{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration of Machine Learning Models\n",
    "As explained in baselineModelTesting.ipynb, we want to predict lap distance given other lap data. We chose to use a Linear Regression algorithm for the baseline model, and got RMSE and MAE values of 1.88 and 0.8 respectively. Now, we will train models on the other candidate algorithms (both with and without cross validation) and compare to this baseline model. These algorithms include KNN, Decision Trees, Random Forests, and Gradient Boosting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secondsdifference</th>\n",
       "      <th>totalpowerin</th>\n",
       "      <th>totalpowerout</th>\n",
       "      <th>netpowerout</th>\n",
       "      <th>distance</th>\n",
       "      <th>amphours</th>\n",
       "      <th>batterysecondsremaining</th>\n",
       "      <th>averagespeed</th>\n",
       "      <th>averagepackCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205000</td>\n",
       "      <td>793.532455</td>\n",
       "      <td>1803.385827</td>\n",
       "      <td>1009.853372</td>\n",
       "      <td>2.814824</td>\n",
       "      <td>97.800003</td>\n",
       "      <td>22425</td>\n",
       "      <td>49.584229</td>\n",
       "      <td>15.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3517768</td>\n",
       "      <td>798.704841</td>\n",
       "      <td>685.739611</td>\n",
       "      <td>-112.965230</td>\n",
       "      <td>4.118535</td>\n",
       "      <td>95.300003</td>\n",
       "      <td>56521</td>\n",
       "      <td>24.939703</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>263001</td>\n",
       "      <td>585.339547</td>\n",
       "      <td>2634.298876</td>\n",
       "      <td>2048.959329</td>\n",
       "      <td>3.974127</td>\n",
       "      <td>93.599998</td>\n",
       "      <td>14468</td>\n",
       "      <td>54.412831</td>\n",
       "      <td>23.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>259000</td>\n",
       "      <td>681.537550</td>\n",
       "      <td>2573.828806</td>\n",
       "      <td>1892.291255</td>\n",
       "      <td>3.987067</td>\n",
       "      <td>91.900002</td>\n",
       "      <td>14517</td>\n",
       "      <td>55.419749</td>\n",
       "      <td>22.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>258500</td>\n",
       "      <td>559.875099</td>\n",
       "      <td>2739.047764</td>\n",
       "      <td>2179.172665</td>\n",
       "      <td>3.994517</td>\n",
       "      <td>90.099998</td>\n",
       "      <td>13283</td>\n",
       "      <td>55.529298</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>317495</td>\n",
       "      <td>537.555507</td>\n",
       "      <td>1679.129062</td>\n",
       "      <td>1141.573555</td>\n",
       "      <td>3.952078</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>740</td>\n",
       "      <td>44.881966</td>\n",
       "      <td>18.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>325001</td>\n",
       "      <td>475.938651</td>\n",
       "      <td>1666.858482</td>\n",
       "      <td>1190.919832</td>\n",
       "      <td>3.963359</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>406</td>\n",
       "      <td>43.894226</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2494999</td>\n",
       "      <td>700.176665</td>\n",
       "      <td>566.324558</td>\n",
       "      <td>-133.852107</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>100215</td>\n",
       "      <td>1.106129</td>\n",
       "      <td>-5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>343500</td>\n",
       "      <td>615.194700</td>\n",
       "      <td>1680.524756</td>\n",
       "      <td>1065.330056</td>\n",
       "      <td>3.963687</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>611</td>\n",
       "      <td>41.645220</td>\n",
       "      <td>17.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>330500</td>\n",
       "      <td>624.008188</td>\n",
       "      <td>1543.656620</td>\n",
       "      <td>919.648432</td>\n",
       "      <td>3.966359</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>300</td>\n",
       "      <td>43.276732</td>\n",
       "      <td>16.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secondsdifference  totalpowerin  totalpowerout  netpowerout  distance  \\\n",
       "3               205000    793.532455    1803.385827  1009.853372  2.814824   \n",
       "4              3517768    798.704841     685.739611  -112.965230  4.118535   \n",
       "5               263001    585.339547    2634.298876  2048.959329  3.974127   \n",
       "6               259000    681.537550    2573.828806  1892.291255  3.987067   \n",
       "7               258500    559.875099    2739.047764  2179.172665  3.994517   \n",
       "..                 ...           ...            ...          ...       ...   \n",
       "202             317495    537.555507    1679.129062  1141.573555  3.952078   \n",
       "203             325001    475.938651    1666.858482  1190.919832  3.963359   \n",
       "204            2494999    700.176665     566.324558  -133.852107  0.181906   \n",
       "205             343500    615.194700    1680.524756  1065.330056  3.963687   \n",
       "206             330500    624.008188    1543.656620   919.648432  3.966359   \n",
       "\n",
       "      amphours  batterysecondsremaining  averagespeed  averagepackCurrent  \n",
       "3    97.800003                    22425     49.584229               15.70  \n",
       "4    95.300003                    56521     24.939703                6.07  \n",
       "5    93.599998                    14468     54.412831               23.29  \n",
       "6    91.900002                    14517     55.419749               22.79  \n",
       "7    90.099998                    13283     55.529298               24.42  \n",
       "..         ...                      ...           ...                 ...  \n",
       "202   3.800000                      740     44.881966               18.49  \n",
       "203   2.100000                      406     43.894226               18.62  \n",
       "204   4.700000                   100215      1.106129               -5.78  \n",
       "205   3.000000                      611     41.645220               17.67  \n",
       "206   1.400000                      300     43.276732               16.79  \n",
       "\n",
       "[199 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# Drop useless columns\n",
    "packetTrainingDataPath=\"../training_data/Elysia.Laps.feather\"\n",
    "df = pd.read_feather(packetTrainingDataPath)\n",
    "df = df.drop(\n",
    "        columns=[\n",
    "            \"msgType\",\n",
    "            \"_id.$oid\",\n",
    "            \"averagepackCurrent.$numberDouble\",\n",
    "            \"timestamp.$numberLong\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "#we need the averagepackCurrent data to be numeric instead of {\"$numberDouble\": \"NaN\"}, setting errors='coerce' sets them to numerical NaN\n",
    "df['averagepackCurrent'] = pd.to_numeric(df['averagepackCurrent'], errors='coerce')\n",
    "\n",
    "#drop the 4 rows with null values\n",
    "df = df.dropna(subset=['distance', 'averagepackCurrent', 'averagespeed'])\n",
    "\n",
    "# Remove outliers from the data\n",
    "#to do this, first define a threshold for outliers (3 standard deviations which contains 99.7% of data)\n",
    "threshold = 3 * np.std(df['distance'])\n",
    "\n",
    "#remove the outliers\n",
    "df = df[(df['distance'] >= -threshold) & (df['distance'] <= threshold)]\n",
    "#remove negative distance values\n",
    "df = df[df['distance'] >= 0]\n",
    "\n",
    "#seperate distance from the other features\n",
    "X = df[['secondsdifference', 'totalpowerin', 'totalpowerout', 'netpowerout', 'amphours', \n",
    "    'averagepackCurrent', 'batterysecondsremaining', 'averagespeed']]\n",
    "y = df['distance']\n",
    "\n",
    "display(df) #should be 199x9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_knn for KNN is: 0.9679120129289978\n",
      "MAE for KNN is: 0.5085657314801215\n"
     ]
    }
   ],
   "source": [
    "#split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69420)\n",
    "\n",
    "#train the model with KNN\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "#get predictions on the test data\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "#evaluate using RMSE and MAE\n",
    "rmse_knn = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"_knn for KNN is: {rmse_knn}\")\n",
    "print(f\"MAE for KNN is: {mae_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE of KNN with Cross Validation is: 1.0697238402389337\n",
      "Average MAE of KNN with Cross Validation is: 0.4079348846084489\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=69420)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "rmse_scores_knn = []\n",
    "mae_scores_knn = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_model.predict(X_val)\n",
    "    \n",
    "    rmse_scores_knn.append(np.sqrt(mean_squared_error(y_val, y_pred_knn)))\n",
    "    mae_scores_knn.append(mean_absolute_error(y_val, y_pred_knn))\n",
    "\n",
    "print(f\"Average RMSE of KNN with Cross Validation is: {np.mean(rmse_scores_knn)}\")\n",
    "print(f\"Average MAE of KNN with Cross Validation is: {np.mean(mae_scores_knn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Decision Trees is: 0.7029586285313585\n",
      "MAE for Decision Trees is: 0.2519436813354493\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69420)\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=69420)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"RMSE for Decision Trees is: {rmse_dt}\")\n",
    "print(f\"MAE for Decision Trees is: {mae_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE of Decision Trees with Cross Validation is: 0.5440475844819632\n",
      "Average MAE of Decision Trees with Cross Validation is: 0.16347548274385076\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=69420)\n",
    "dt_model = DecisionTreeRegressor(random_state=69420)\n",
    "\n",
    "rmse_scores_dt = []\n",
    "mae_scores_dt = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    dt_model.fit(X_train, y_train)\n",
    "    y_pred_dt = dt_model.predict(X_val)\n",
    "    \n",
    "    rmse_scores_dt.append(np.sqrt(mean_squared_error(y_val, y_pred_dt)))\n",
    "    mae_scores_dt.append(mean_absolute_error(y_val, y_pred_dt))\n",
    "\n",
    "print(f\"Average RMSE of Decision Trees with Cross Validation is: {np.mean(rmse_scores_dt)}\")\n",
    "print(f\"Average MAE of Decision Trees with Cross Validation is: {np.mean(mae_scores_dt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random Forests is: 0.9136314836987844\n",
      "MAE for Random Forests is: 0.37793798720556715\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69420)\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=69420)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"RMSE for Random Forests is: {rmse_rf}\")\n",
    "print(f\"MAE for Random Forests is: {mae_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE of Random Forests with Cross Validation is: 0.5354677709271433\n",
      "Average MAE of Random Forests with Cross Validation is: 0.2040573819672439\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=69420)\n",
    "rf_model = RandomForestRegressor(random_state=69420)\n",
    "\n",
    "rmse_scores_rf = []\n",
    "mae_scores_rf = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "    \n",
    "    rmse_scores_rf.append(np.sqrt(mean_squared_error(y_val, y_pred_rf)))\n",
    "    mae_scores_rf.append(mean_absolute_error(y_val, y_pred_rf))\n",
    "\n",
    "print(f\"Average RMSE of Random Forests with Cross Validation is: {np.mean(rmse_scores_rf)}\")\n",
    "print(f\"Average MAE of Random Forests with Cross Validation is: {np.mean(mae_scores_rf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Gradient Boosting is: 0.9272863715854762\n",
      "MAE for Gradient Boosting is: 0.3428877079711604\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69420)\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=69420)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"RMSE for Gradient Boosting is: {rmse_gb}\")\n",
    "print(f\"MAE for Gradient Boosting is: {mae_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE of Gradient Boosting with Cross Validation is: 0.4070252257043531\n",
      "Average MAE of Gradient Boosting with Cross Validation is: 0.14665131782949836\n",
      "Minimum distance: 0.0162265625\n",
      "Maximum distance: 8.745853515625\n",
      "Average distance: 4.063722782813743\n",
      "25th percentile of distance: 3.963570068359375\n",
      "50th percentile (median) of distance: 3.9834296875\n",
      "75th percentile of distance: 4.0039501953125\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=69420)\n",
    "gb_model = GradientBoostingRegressor(random_state=69420)\n",
    "\n",
    "rmse_scores_gb = []\n",
    "mae_scores_gb = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred_gb = gb_model.predict(X_val)\n",
    "    \n",
    "    rmse_scores_gb.append(np.sqrt(mean_squared_error(y_val, y_pred_gb)))\n",
    "    mae_scores_gb.append(mean_absolute_error(y_val, y_pred_gb))\n",
    "\n",
    "print(f\"Average RMSE of Gradient Boosting with Cross Validation is: {np.mean(rmse_scores_gb)}\")\n",
    "print(f\"Average MAE of Gradient Boosting with Cross Validation is: {np.mean(mae_scores_gb)}\")\n",
    "\n",
    "min_distance = df['distance'].min()\n",
    "max_distance = df['distance'].max()\n",
    "average_distance = df['distance'].mean()\n",
    "percentile_25 = np.percentile(df['distance'], 25)\n",
    "percentile_50 = np.percentile(df['distance'], 50)\n",
    "percentile_75 = np.percentile(df['distance'], 75)\n",
    "\n",
    "print(\"Minimum distance:\", min_distance)\n",
    "print(\"Maximum distance:\", max_distance)\n",
    "print(\"Average distance:\", average_distance)\n",
    "print(f\"25th percentile of distance: {percentile_25}\")\n",
    "print(f\"50th percentile (median) of distance: {percentile_50}\")\n",
    "print(f\"75th percentile of distance: {percentile_75}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and Evaluation on Performance\n",
    "\n",
    "### Ranking Criteria\n",
    "As mentioned in the conclusion of baselineModelTesting, we want low MAE and RMSE scores, with a priority on lower MAE over RMSE. \n",
    "\n",
    "### Model Performance\n",
    "1. **Gradient Boosting with Cross Validation**\n",
    "    - **MAE:** 0.1467\n",
    "    - **RMSE:** 0.4070\n",
    "\n",
    "2. **Decision Trees with Cross Validation**\n",
    "    - **MAE:** 0.1635\n",
    "    - **RMSE:** 0.5440\n",
    "\n",
    "3. **Random Forests with Cross Validation**\n",
    "    - **MAE:** 0.2041\n",
    "    - **RMSE:** 0.5355\n",
    "\n",
    "4. **Decision Trees**\n",
    "    - **MAE:** 0.2519\n",
    "    - **RMSE:** 0.7030\n",
    "\n",
    "5. **Gradient Boosting**\n",
    "    - **MAE:** 0.3429\n",
    "    - **RMSE:** 0.9273\n",
    "\n",
    "6. **Random Forests**\n",
    "    - **MAE:** 0.3779\n",
    "    - **RMSE:** 0.9136\n",
    "\n",
    "7. **KNN with Cross Validation**\n",
    "    - **MAE:** 0.4079\n",
    "    - **RMSE:** 1.0697\n",
    "\n",
    "8. **KNN**\n",
    "    - **MAE:** 0.5086\n",
    "    - **RMSE:** 0.9679\n",
    "\n",
    "### Summary\n",
    "Based on the MAE scores, the models are ranked as follows:\n",
    "1. Gradient Boosting with Cross Validation\n",
    "2. Decision Trees with Cross Validation\n",
    "3. Random Forests with Cross Validation\n",
    "4. Decision Trees\n",
    "5. Gradient Boosting\n",
    "6. Random Forests\n",
    "7. KNN with Cross Validation\n",
    "8. KNN\n",
    "\n",
    "Gradient Boosting with Cross Validation performed the best with the lowest MAE and RMSE scores, at 0.1467 and 0.4070 respectively. Because the majority of our data is between 3.9-4.0 and MAE is 0.1467, it means predictions are normally 3.67% to 3.76% off from the real distance value. This is a significant improvement from the baseline model, which had predictions which were 20% different. \n",
    "\n",
    "In the real world, this model can predict the distance of a lap within 0.1467 units given features like `amphours`, `averagepackCurrent`, `batterysecondsremaining`, and `averagespeed`. This prediction will be useful when making data driven decisions like in optimizing lap performance, analysing energy consumption, and looking at overall efficiency. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
